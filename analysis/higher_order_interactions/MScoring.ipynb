{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process results directory and return a pivot table with feature importance\n",
    "def process_results_directory(root_dir, meaningful_parts):\n",
    "    all_data = []  # List to store all data\n",
    "    \n",
    "    # Walk through the directory tree\n",
    "    for subdir, dirs, files in os.walk(root_dir):\n",
    "        # Check if subdir contains 'ABS' or 'MutualInformation'\n",
    "        if 'ABS' in subdir or 'MutualInformation' in subdir:\n",
    "            if subdir != root_dir:  # Ensure not processing the root directory\n",
    "                method = subdir.split(os.sep)[-1].replace('ABS_', '')  # Extract method name from subdir\n",
    "                subdir_data = []  # List to store data for current subdir\n",
    "                for file in files:\n",
    "                    if file.endswith('.txt'):  # Process only .txt files\n",
    "                        file_path = os.path.join(subdir, file)  # Construct file path\n",
    "                        try:\n",
    "                            data = pd.read_csv(file_path, delimiter='\\t')  # Read data from file\n",
    "                            m_data = data[data['Feature'].str.startswith('M')]  # Filter data for features starting with 'M'\n",
    "                            importance_cols = [col for col in data.columns if \"Feature_Importance\" in col]  # Find importance columns\n",
    "\n",
    "                            # Iterate over filtered data and importance columns\n",
    "                            for index, row in m_data.iterrows():\n",
    "                                for col in importance_cols:\n",
    "                                    importance_type = col.replace('Feature_Importance', '').strip()  # Extract importance type\n",
    "                                    method_column_name = f\"{method}_{importance_type}\".rstrip('_')  # Create method column name\n",
    "                                    entry = {\n",
    "                                        'Feature': row['Feature'],  # Feature name\n",
    "                                        'Method': method_column_name,  # Method and importance type\n",
    "                                        'Importance': row[col],  # Importance value\n",
    "                                        **meaningful_parts  # Add meaningful parts\n",
    "                                    }\n",
    "                                    subdir_data.append(entry)  # Add entry to subdir_data\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error reading {file_path}: {e}\")  # Print error if reading fails\n",
    "\n",
    "                if subdir_data:\n",
    "                    all_data.extend(subdir_data)  # Add subdir data to all_data\n",
    "\n",
    "    if all_data:\n",
    "        results_df = pd.DataFrame(all_data)  # Create DataFrame from all_data\n",
    "        pivot_df = results_df.pivot_table(index=['Feature', *meaningful_parts.keys()], columns='Method', values='Importance', aggfunc='mean').reset_index()\n",
    "        # Get the current non-Method columns\n",
    "        non_method_cols = ['Feature', *meaningful_parts.keys()]\n",
    "        # Get the current Method columns and sort them as required\n",
    "        method_cols = [col for col in pivot_df.columns if col not in non_method_cols]\n",
    "        sorted_method_cols = ['ReliefF10', 'ReliefF10_ABS', 'ReliefF', 'ReliefF_ABS', 'MultiSURF', 'MultiSURF_ABS', 'MultiSURFstar', 'MultiSURFstar_ABS', 'MutualInformation']\n",
    "        # Combine the non-Method columns with the sorted Method columns\n",
    "        pivot_df = pivot_df[non_method_cols + sorted_method_cols]\n",
    "        return pivot_df  # Return the pivot table\n",
    "    else:\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if no data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_numeric_parts(s):\n",
    "    \"\"\"Extract numeric parts from a string and return as a tuple of integers.\"\"\"\n",
    "    # Use regular expression to find all sequences of digits in the string\n",
    "    # Convert each sequence of digits to an integer and return them as a tuple\n",
    "    return tuple(map(int, re.findall(r'\\d+', s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_process_results(start_dir):\n",
    "    master_df = pd.DataFrame()  # Initialize an empty DataFrame to store the master results\n",
    "    for root, dirs, files in os.walk(start_dir):  # Walk through the directory tree\n",
    "        if 'Results' in dirs:  # Check if 'Results' directory exists in the current directory\n",
    "            path_parts = os.path.relpath(root, start_dir).split(os.sep)  # Get the relative path parts\n",
    "            meaningful_parts = {}  # Dictionary to store meaningful parts\n",
    "            for part in path_parts:  # Iterate over path parts - will need to update this for new descriptors if needed\n",
    "                if 'xor_' in part:\n",
    "                    meaningful_parts['X1'] = part  # Order of epistasis with additional descriptors\n",
    "                elif 'a_' in part:\n",
    "                    meaningful_parts['X2'] = part  # Feature count\n",
    "\n",
    "            results_dir = os.path.join(root, 'Results')  # Construct the path to the 'Results' directory\n",
    "            print(f\"Processing 'Results' folder at: {results_dir}\")\n",
    "            results_df = process_results_directory(results_dir, meaningful_parts)  # Process the results directory\n",
    "            if not results_df.empty:  # If the results DataFrame is not empty\n",
    "                csv_path = os.path.join(results_dir, 'M_average_feature_importance.csv')  # Path to save the results CSV\n",
    "                results_df.to_csv(csv_path, index=False)  # Save the results DataFrame to a CSV file\n",
    "                print(f\"Average feature importance results saved to {csv_path}\")\n",
    "\n",
    "                # Create a numeric tuple for sorting X1\n",
    "                results_df['X1_numeric'] = results_df['X1'].apply(extract_numeric_parts)\n",
    "                \n",
    "                # Append to the master DataFrame\n",
    "                master_df = pd.concat([master_df, results_df], ignore_index=True)\n",
    "\n",
    "    # Sort the master DataFrame\n",
    "    if not master_df.empty:  # If the master DataFrame is not empty\n",
    "        master_df = master_df.sort_values(by=['X1_numeric', 'Feature'])  # Sort by numeric parts of X1 and Feature\n",
    "        master_df.drop('X1_numeric', axis=1, inplace=True)  # Remove the auxiliary column after sorting\n",
    "        master_csv_path = os.path.join(start_dir, 'M_master_feature_importance.csv')  # Path to save the master CSV\n",
    "        master_df.to_csv(master_csv_path, index=False)  # Save the master DataFrame to a CSV file\n",
    "        print(f\"Master feature importance results saved to {master_csv_path}\")  # Print confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the process from the current working directory\n",
    "find_and_process_results('.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
